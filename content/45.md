Title: Infrastructure de FamiHero Partie 1
Date: 2013-04-15 10:02
Author: cyrilb
Category: haproxy, infra, linux, nginx
Tags: haproxy, infra, linux, nginx
Slug: 45

Mettre en place une infrastructure, ça peut faire peur. Par où
commencer? Avec quelles briques? De quoi ai-je vraiment besoin? Et si je
testais le dernier système de cache à la mode?

J’ai compris que je m’éparpillais trop, je suis donc revenu aux
basiques, grâce au conseil tout simple d’un ancien collègue: « Fais ce
que tu sais faire ». A partir de là, ça a été un jeu d’enfants, et j’ai
compris que ça m’aurait pris un temps fou d’acquérir de nouvelles
compétences sur des sujets que je ne maitrisais pas du tout, et que mon
expérience était largement suffisante pour mettre en place une
architecture telle que je les aime:

***- Entièrement Scalable***

***- Hautement disponible***

***- KISS (Keep It Simple Stupid)***

Le but de ce post est de vous faire partager la mise en place de
l’infrastructure chez FamiHero, de manière pragmatique, sans trop
rentrer dans le détail en général mais en approfondissant certains
points. Je pense que certains vieux admins, bien plus compétents que
moi, souriront devant la naïveté de certains passages, mais j’aime
imaginer que cela pourra rendre service à certains admins junior.

**1. L’infrastructure en elle même, première partie**

**  
**Comme vous pouvez le constater, c’est du grand classique, qui n’a pas
le mérite d’innover, mais de répondre à mes besoins. On va se concentrer
sur le load-balancing qui va aller taper nos frontaux pour commencer.


**2. Load Balancers et ip flottante**

Si on met de côté les load-balancers de type hard (Cisco, f5, etc), je
ne connais que trois solutions qui font le travail:

**- Varnish**

Varnish a des possibilités vraiment intéressantes pour faire du load
balancing grâce à un système de backends vraiment simples à gérer. On y
retrouve du très courants avec des priorités, des poids, des health
check etc… Le soucis, c’est que c’est avant tout un formidable système
de cache, et que je préfère l’utiliser pour sa fonction première, le
cache, qui a du faire preuve de plus d’attention par ses développeurs.

**- Nginx**

Nginx, non content d’être un excellent serveur web, peut aussi
s’ennorgueuilir d’être un excellent load balancer qui fonctionne à
merveille. On verra un peu plus loin que je m’en sers pour faire un peu
de proxy-pass.

**- Haproxy**

La Rolls Royce des loads balancers. Mon choix s’est bien sûr porté sur
lui parce que je m’en suis déjà servi pas mal de temps chez Twenga; je
sais donc qu’il répond à mes besoins et qu’il a des milliers d’options
super sympas.

On commence par récupérer les sources. La version stable actuelle est la
1.4.22 mais pour ma part je suis sur la branche de développement, la
1.5.\*. Suivez avec attention la mailling-list de haproxy, elle regorge
de détails pratiques sur les branches en développement. L’intérêt de la
branche 1.5 est qu’elle embarque l’offloading en SSL, on y reviendra un
peu plus loin.

**Récupération des sources et installation**

```bash
cyril@lb2:~$ cd /usr/local/src/
cyril@lb2:/usr/local/src$ sudo apt-get install make gcc libpcre3-dev libssl-dev
cyril@lb2:/usr/local/src$ wget http://haproxy.1wt.eu/download/1.5/src/snapshot/haproxy-ss-20120905.tar.gz
cyril@lb2:/usr/local/src$ tar xfz haproxy-ss-20120905.tar.gz
cyril@lb2:/usr/local/src$ cd haproxy-ss-20120905/
cyril@lb2:/usr/local/src$ make TARGET=linux2628 USE_STATIC_PCRE=1 USE_OPENSSL=1
cyril@lb2:/usr/local/src$ sudo make PREFIX=/opt/haproxy-ssl install
```

**Configuration de Haproxy**

**  
**On commence par ajouter l’utilisateur qui lancera haproxy. Choisissez
un nom le moins générique possible.

```bash
cyril@lb2:~$ sudo useradd bingoha
```

Dans le répertoire examples vous trouverez un haproxy.cfg. A vous de
construire le vôtre suivant vos besoins. Pour moi au final ça donne ça:

```bash
global
# On renvoit info/notice vers syslog, je reviendrai un peu plus loin sur la configuration des logs haproxy avec rsyslog.
log /dev/log local0 info
log /dev/log local0 notice
# Total de connexions simultanées en concurrence 
maxconn 20000
#L'utilisateur et le groupe qui lance haproxy
user bingoha
group bingoha
# Création d'un socket unix en mode stream, me permet de chopper plein d'informations, voir plus loin.
stats socket /var/run/haproxy.stat level admin
# Un mec pas commode
daemon

defaults
# Protocole par défaut de l'instance
mode http
# Log par défaut, le log est émis dés qu'une connexion est initiée
log global
# Renvoie une 503 ou une 504 si la connexion au serveur n'a pas abouti
timeout connect 5s
# Temps maximum d'inactivité côté client
timeout client 20s
# Temps maximum d'inactivité côté serveur
timeout server 15s
# Un check additionnel du timeout, mais apres qu'une connexion ait déjà été établie.
timeout check 2s
# Temps maximum alloué pour attendre une nouvelle connexion http
timeout http-keep-alive 1s
# Temps maximum alloué pour attendre une requête http complète, on peut s'en servir comme protection contre les slowloris
timeout http-request 50s

# L'interface web de management
listen web-mgt
bind 78.109.93.62:8089
# Aucun intérêt de logger les connexions sans erreur
option dontlog-normal
mode http
stats uri /haproxy
# On "protège l'accès à l'interface par un user/password
stats realm STATS_WEB
stats auth admin:4nth0nIB4uG|l
# Refresh des stats toutes les 15 secondes
stats refresh 15s

# Notre frontend
frontend http-in
# Ecoute sur le port 80
bind *:80
# Activation des logs sur les requêtes et les sessions
option httplog
# insertion du header X-Forwarded-For header aux requêtes envoyées aux serveurs
option forwardfor
# Active la fermeture des connexions côté serveur
option http-server-close
# C'est grâce à cette ligne qu'on peut offloader en https, je reviens dessus plus loin
#bind *:443 ssl crt /etc/stunnel/certifami/famihero.pem nosslv3 prefer-server-ciphers ciphers RC4-SHA:AES128-SHA:AES256-SHA

# Acl basique, tout ce qui commence par mon. ou man. est dirigé vers un backend sépcial
acl acl_others hdr_beg(host) -i mon. man.
use_backend www.famihero.others if acl_others

# Même chose qu'en haut, mais sur un autre backend
acl acl_vhosts hdr_beg(host) -i devil. dev1. dev2. ppdev1. ppdev2. sandbox.
use_backend www.vhosts.dev if acl_vhosts

# Acl basique, sert surtout de default_backend en fait
acl acl_prod hdr_end famihero.com famihero.com. zenanny.com zenanny.com.
use_backend www.famihero.com if acl_prod

default_backend www.famihero.com

# Le nom du backend
backend www.famihero.com
# L'algo de load balancing du backend
balance roundrobin
# Insertion d'un cookie
cookie fami insert indirect nocache domain .famihero.com
# Check server health en mode http sur ce fichier (on peut tres bien utiliser un GET à la place du HEAD)
option httpchk HEAD /haproxytest.txt HTTP/1.0
# Mes serveurs web. Un check toutes les 2 secondes et on etime qu'ils sont morts apres 2x2 secondes d'uncheck
server web1 192.168.2.3:80 check inter 2000 fall 2
server web2 192.168.2.4:80 check inter 2000 fall 2
server web3 192.168.2.5:80 check inter 2000 fall 2
server web4 192.168.2.13:80 check inter 2000 fall 2
# Le trafic est redirigé sur ce serveur web si tous les autres serveurs ne répondent plus grâce au mode backup
server maintenance 127.0.0.1:8787 backup
# Active la redistribution de session en cas de perte de connexion sur un serveur
option redispatch
# Utile en cas de grosse charge, permet de dropper les requêtes avortées pour qu'elles ne s'empilent pas
option abortonclose
# Supprime des headers l'ip des webs
rspidel ^Set-cookie:\ IP=

backend www.famihero.others
server mon 192.168.2.12:80

backend www.vhosts.dev
server web3 192.168.2.5:8687
option http-server-close
option forwardfor
option abortonclose

# Un autre backend, celui-ci fonctionne en mode tcp
listen services
bind *:7879
mode tcp
server lead3-vp.famihero.com 192.168.2.5:7879
```

**Quelques scripts, tips and tricks.**


Voici un script que j’ai écrit pour rentrer et sortir des serveurs du
proxy. Il est vraiment tout bête mais je m’en sers tous les jours. Il
faudra que je trouve le temps de l’améliorer, genre rajouter une
fonction sur les stats de trafic, etc… Il est très facilement adaptable,
libre à vous de l’améliorer bien sûr. Vous pouvez le télécharger ICI ou
le parcourir ci-dessous:


```bash
    #!/bin/bash

    #set -e

    WEBSERVER="$2"
    SOCQUETTE="socat unix-connect:/var/run/haproxy.stat stdio"
    SERVERS="web1 web2 web3 web4"
    BACKEND="www.famihero.com"
    VERT="\\033[1;32m"
    ROUGE="\\033[1;31m"
    NORMAL="\\033[0;39m"

    print_help() {
    cat &lt;&lt; EOF

    Script to manage servers in HaProxy - Read README.TXT
    Copyright (c) Cyril Beaufrere 
    Version: 0.7
    Last Modified: 10 Mars 2013
    License: This software can be used for free unless I meet you, then you owe me lunch.

    Usage: wwwcluster.sh -d| -e| -a| -h| -m| -s [webserver]

    Options:

    -d [webserver]: To disable server
    -e [webserver]: To enable server
    -a: Enable all servers
    -h: This stupid help
    -m: Disable all servers (maintenance mode)
    -s: Show status of all web servers

    EOF
            }


    disable_server () {
    echo -e "$ROUGE""---------------------------------- " "$NORMAL"
    echo "Do you want to disable $WEBSERVER? (y/n)"
    echo -e "$ROUGE""---------------------------------- " "$NORMAL"
    read reponse
     if [[ $reponse == "y" ]]
     then echo disable server $BACKEND/$WEBSERVER | $SOCQUETTE
     sleep 2
     echo show stat | $SOCQUETTE  | grep $WEBSERVER | grep -v check | awk -F'[,|]' '{print $2 " ===&gt; "$18}' OFS=","
    fi
     if [[ $reponse == "n" ]]
     then echo "###Leaving###"
    fi
    }


    enable_server () {
    echo -e "$VERT""---------------------------------- " "$NORMAL"
    echo "Do you want to enable $WEBSERVER? (y/n)"
    echo -e "$VERT""---------------------------------- " "$NORMAL"
    read reponse
     if [[ $reponse == "y" ]]
     then echo enable server $BACKEND/$WEBSERVER | $SOCQUETTE
     sleep 2
     echo -e show stat | $SOCQUETTE | grep $WEBSERVER | grep -v check | awk -F'[,|]' '{print $2 " ===&gt; "$18}' OFS=","
    fi
     if [[ $reponse == "n" ]]
     then echo "###Leaving###"
    fi
    }


    maintenance () {
    echo -e "$ROUGE""---------------------------------------- " "$NORMAL"
    echo "Do you want to enable maintenance? (y/n)"
    echo -e "$ROUGE""---------------------------------------- " "$NORMAL"
    read reponse
     if [[ $reponse == "y" ]]
     then
     for i in $SERVERS
     do
     echo disable server $BACKEND/$i | $SOCQUETTE
     sleep 2
     done
    check_status
    fi
         if [[ $reponse == "n" ]]
         then echo "###Leaving###"
    fi 
    }

    enable_all () {
    echo "Do you want to enable all servers? (y/n)"
    read reponse
            if [[ $reponse == "y" ]]
            then
            for i in $SERVERS
            do
            echo enable server $BACKEND/$i | $SOCQUETTE
            sleep 2
            done
    check_status
    fi
         if [[ $reponse == "n" ]]
         then echo "###Leaving###"
    fi
    }


    check_status () {
    for i in $SERVERS
    do
    echo show stat | $SOCQUETTE | grep $i | grep -v check | awk -F'[,|]' '{print $2 "===&gt;"$18}' OFS="," 
            done
    }

    if (($# == 0)); then
    print_help
    fi

    while getopts smdeha pouet
    do case "$pouet" in
     d) disable_server;;
     e) enable_server;;
     [?]) print_help;;
     '#$') print_help;;
     a) enable_all;;
     s) check_status;;
     m) maintenance;;
     h) print_help;;

     esac
    done
```
 

Exemple pour ce que ça donne concrètement:


- Sortir un serveur du cluster:

```bash
    prod@lb1:~# ./wwwcluster.sh -d web2
    ----------------------------------  
    Do you want to disable web2? (y/n)
    ----------------------------------  
    y

    web2 ===>; MAINT
```


- Afficher l’état des serveurs:

```bash
    prod@lb1:~# ./wwwcluster.sh -s
    web1===>UP
    web2===>MAINT
    web3===>UP
    web4===>DOWN
    prod@lb1:~# 
```

Je vous laisse tester les autres fonctions…


**Renvoyer les logs haproxy vers syslog:**


On se souvient de ces deux lignes dans notre configuration de Haproxy:

```bash
    log /dev/log local0 info
    log /dev/log local0 notice
```

Sous Ubuntu, RSyslog est installé de base, il nous suffit donc de le
configurer afin d’envoyer les logs vers où bon nous semble. Pour ma part
je me suis contenté de rajouter dans mon /etc/rsyslog/d/ un fichier
haproxy.conf qui a cette forme:

```bash
    if ($programname == 'haproxy' and $syslogseverity-text == 'info') then -/var/log/haproxy/haproxy-info.log
    &amp; ~
    if ($programname == 'haproxy' and $syslogseverity-text == 'notice') then -/var/log/haproxy/haproxy-notice.log
    &amp; ~
```


Un reload de Rsyslog plus tard, j’ai bien mes info et notice qui sont
renvoyés vers mon /var/log/haproxy/haproxy-\*.log.

Et n’oubliez pas d’adapter votre sysctl.conf pour accroitre les
performances (à adapter suivant votre configuration et vos besoins):

```bash
    net.ipv4.tcp_tw_reuse = 1
    net.ipv4.ip_local_port_range = 1024 65023
    net.ipv4.tcp_max_syn_backlog = 10240
    net.ipv4.tcp_max_tw_buckets = 400000
    net.ipv4.tcp_max_orphans = 60000
    net.ipv4.tcp_synack_retries = 3
    net.core.somaxconn = 10000

    net.ipv4.tcp_syncookies = 1
    net.ipv4.conf.all.rp_filter = 1
    net.ipv4.tcp_max_syn_backlog = 1024
```
 
**La gestion du HTTPS:**

J’ai commencé par
configurer [stunnel](https://www.stunnel.org/index.html "stunnel") qui
fait ça très bien, et qui s’installe et se configure en 30 secondes. Ca
fonctionnait tres tres bien, mais sous grosse charge je me suis rendu
compte que stunnel avait des comportements bizarres. J’ai donc essayé le
offloading ssl avec HaProxy qui lui aussi fonctionnait tres bien, mais
sur une version de développement. L’argent étant le nerf de la guerre,
en attendant que l’offload SSL soit implanté en version stable dans
HaProxy, je me suis dirigé sur un proxy nginx tout simple qui est rompu
à l’exercice, voici juste un bout de la configuration afin d’illustrer
le proxy\_pass qui écoute sur le port 443 et renvoie vers… Haproxy.


```bash
                ssl_certificate /etc/ssl/private/famihero.crt;
                ssl_certificate_key /etc/ssl/private/famihero.key;
         ssl_client_certificate /etc/ssl/certs/GandiStandardSSLCA.pem;

                location / {
                    proxy_pass http://127.0.0.1:80$request_uri;
```


**3. Corosync et Pacemaker**


Vous l’aurez remarqué, je parle d’ip flottante au début. C’est sur cette
adresse ip qu’arrivent les requêtes qui sont ensuite rebalancées au load
balancer actif. Cas pratique:

Si lb1 tombe pour une raison ou une autre, l’ip redirige le trafic
automatiquement et de manière totalement transparente pour l’utilisateur
vers lb2 qui devient le load balancer actif.

Il faut bien évidemment avoir deux load balancers avec une configuration
identique (haproxy, nginx, memcache, etc…).

Pour bénéficier de la haute disponibilité au niveau des proxys, j’ai
utilisé le couple corosync/pacemaker. Ce sont deux softs relativement
complexes et je ne dois m’en servir qu’à 10% de leurs possibilités, mais
ils font vraiment bien leur taffe.

**Installation et configuration.**

Comme Pacemaker utilise corosync de base sous Ubuntu j’ai juste lancé un
apt-get install pacemaker. La configuration en elle même est très
facile, surtout pour ceux qui connaissent un peu Cisco.

Juste après l’installation, il faut éditer le fichier
/etc/default/corosync et setter à ‘yes’ pour que corosync se lance au
boot:

```bash
    prod@lb1:~# cat /etc/default/corosync 
    # start corosync at boot [yes|no]
    START=yes
```

On fera bien évidement la même chose sur le second load-balancer.

Il nous faut ensuite générer une clef d’authentification sur un des deux
load-balancers avec la commande:

```bash
    cyril@lb1:~# sudo corosync-keygen
```

Qui va aller créer un fichier /etc/corosync/authkey. On recopie cette
clef sur lb2 puis on édite ensuite le fichier
/etc/corosync/corosync.conf et on configure la partie interface avec vos
informations réseau.

```bash
      interface {
      # Votre numéro d'interface 
      ringnumber: 0
                    # Le réseau utilisé sur la carte. Loopback par défaut.
      #bindnetaddr: 127.0.0.1 
      bindnetaddr: 78.109.93.0
                    # L'adresse de multicast pour les tests
      mcastaddr: 226.94.1.1
                    # Port à utiliser pour le multicast
      mcastport: 5405
     }
```
 
On va ensuite lancer corosync:

```bash
    cyril@lb1:/# sudo /etc/init.d/corosync start
```

Un simple crm\_mon vous permettra de voir que corosync tourne bien. Il
suffit maintenant de configurer la CIB, soit la Configuration
Information Base. C’est une fois de plus tres simple.

On va utiliser la commande crm pour rentrer en mode commande en ligne:

```bash
    cyril@lb2:~# sudo crm
    crm(live)# 
```

Puis on crée notre première configuration:

```bash
    crm(live)# cib new configlbfami201211
    INFO: configlbfami201211 shadow CIB created
    crm(configlbfami201211)#
    crm(configlbfami201211)# configure
    crm(configlbfami201211)configure#
    crm(configlbfami201211)configure# property stonith-enabled=false
```
 
et c’est parti pour la configuration de notre ip virtuelle:

```bash
    crm(configlbfami201211)configure# primitive vip ocf:heartbeat:IPaddr2 params ip="78.109.93.62" nic="eth0" cidr_netmask="24" op start interval="0s" timeout="60s" op monitor interval="5s" timeout="20s" op stop interval="0s" timeout="60s"
```

On peut bien sûr configurer idéalement plusieurs ip virtuelles, chacune
pour une utilisation bien différente (intranet, contenu statique, etc),
voire même rajouter un autre load-balancer.

Il ne nous reste plus qu’à vérifier la config mise en place et de la
commiter:

```bash
    crm(configlbfami201211)configure# verify
    crm(configlbfami201211)configure# end
    There are changes pending. Do you want to commit them? y
    crm(configlbfami201211)#
    crm(configlbfami201211)# cib use live
    crm(live)# cib commit configlbfami201211
    INFO: commited 'configlbfami201211' shadow CIB to the cluster
    crm(live)# quit
    bye
```

C’est fini, ça n’a pas pris plus de 2 minutes, même si dans ce cas la
problématique est simplissime (assurer la haute dispo de deux nodes, lb1
et lb2 sur une ip virtuelle) et que nous ne sommes pas du tout rentré
dans les questions de quorums, etc… On peut vérifier notre configuration
avec un ‘crm\_mon’:

```bash
    ============
    Last updated: Mon Apr 15 16:21:35 2013
    Last change: Sun Nov  25 23:58:42 2012 via cibadmin on lb1
    Stack: openais
    Current DC: lb1 - partition with quorum
    Version: 1.1.7-ee0730e13d124c3d58f00016c3376a1de5323cff
    2 Nodes configured, 2 expected votes
    1 Resources configured.
    ============

    Online: [ lb1 lb2 ]

    vip     (ocf::heartbeat:IPaddr2):       Started lb1
```

Ou avec crm en lançant:

```bash
    cyril@lb2:~# sudo crm configure
    crm(live)configure# show
    node lb1
    node lb2
    primitive vip ocf:heartbeat:IPaddr2   
    params ip="78.109.93.62" nic="eth0" cidr_netmask="24"   
    op start interval="0s" timeout="60s"   
    op monitor interval="5s" timeout="20s"   
    op stop interval="0s" timeout="60s"
    property $id="cib-bootstrap-options"   
    dc-version="1.1.7-ee0730e13d124c3d58f00016c3376a1de5323cff"   
    cluster-infrastructure="openais"   
    expected-quorum-votes="2"   
    stonith-enabled="false"   
    no-quorum-policy="ignore"
    crm(live)configure# exit
    bye
```

Quelques commandes pratiques avec le Cluster Resource Manager, du genre
migrer l’ip flottante sur lb2 pour faire une opération de maintenance
sur lb1:

```bash
    cyril@lb2:~# sudo crm
    crm(live)# resource
    crm(live)resource# list
    failover-ip     (ocf::heartbeat:IPaddr) Started
    crm(live)resource# migrate failover-ip lb2
    crm(live)resource# bye
    bye
```

Bref, c’est tout simple à mettre en place et c’est d’une robustesse et
d’une facilité incroyable.

**4. Nginx**

Les frontaux sont bien sûr tous sur nginx. C’est léger, véloce, et c’est
un régal à configurer.

**Installation:**

```bash
    prod@web4:~# cd /usr/local/src/
    prod@web4:~# tar xfz nginx-1.2.8.tar.gz 
    prod@web4:~# cd nginx-1.2.8/
    prod@web4:~# ./configure --with-http_gzip_static_module --with-http_stub_status_module --with-http_ssl_module --with-http_realip_module
    prod@web4:~# sudo make
    prod@web4:~# sudo make install
```

Rien de bien particulier, ça prend 30 secondes.

La mise en place de la configuration nécessite de prendre un peu plus de
temps et pas mal de tests pour trouver la meilleure combinaison
possible.

Vous faire un copier/coller de la configuration (nginx.conf) n’a que peu
d’intérêt, aussi on va juste regarder quelques paramètres non-vanilla:

On se souvient qu’on a compilé nginx avec le
module [–with-http\_realip\_module](http://wiki.nginx.org/HttpRealipModule "HttpRealipModule"),
ça va nous servir à recevoir les ip des clients plutôt que l’ip du
load-balancer.

```bash
    set_real_ip_from   10.17.9.3;
    real_ip_header X-Forwarded-For;
```

On prend bien soin de calibrer les timeouts:

```bash
    client_body_timeout   60;
    client_header_timeout 60;
    keepalive_timeout     60 60;
    send_timeout          60;
```

On ajoute quelques options de bon sens:

```bash
    ignore_invalid_headers   on;
    recursive_error_pages    on;
    sendfile                 on;
    server_name_in_redirect off;
    server_tokens           off;

    tcp_nodelay on;
    tcp_nopush  on;
```

Et la compression, ça serait impensable de ne pas l’utiliser:

```bash
      gzip              on;
      #gzip_static       on;
      gzip_buffers      16 8k;
      gzip_comp_level   9;
      gzip_http_version 1.1;
      gzip_min_length   1000;
      gzip_types application/x-javascript application/json text/css text/plain image/x-icon image/bmp image/png image/gif text/javascript;
      gzip_vary         on;
      gzip_proxied any;
```


Toutes ces commandes se retrouvent dans
le [HttpCoreModule](http://wiki.nginx.org/HttpCoreModule "HttpCoreModule"),
quand je me mets à le lire je découvre plein de nouvelles choses et du
coup je passe pas mal de temps à voir ce que je peux optimiser ou mieux
faire avec.

Je mets par habitude mes sites dans un repertoire à part. Certains
créent aussi un lien symbolique sur un autre répertoire avec du
site-available pour faire comme avec Apache.

```bash
    include /usr/local/nginx/conf/sites-enabled/*;
```

La configuration du serveur est tout aussi palpitante, rien de
particulier si ça n’est la partie server\_name que j’ai décliné comme ça
(pour jouer avec les différents server\_namer que je possède):

```bash
    set $lead_domain_name www.famihero.com;
    if ($http_host != $lead_domain_name) {
    rewrite  ^(.*)$  http://$lead_domain_name$1 permanent;
    }
```

J’aurai aussi pu faire ça comme ça mais c’est moins sexy et moins
pratique:

```bash
    if ($http_host ~* (www.famihero.fr|famihero.fr|www.famiheros.com|famiheros.com|etc...) ) {
    rewrite  ^/(.*)$  http://www.famihero.com/$1  permanent;
    }
```

On va aussi penser à ne pas logger les check de haproxy pour ne pas
pourrir les logs:

```bash
    location /haproxytest.txt {
    access_log off;
    }
```

La partie pour les static fait l’objet d’une configuration à part qui
donne ça:

```bash

    server {
        server_name     statics.famihero.com;
        root /var/www/static3/current/web;

        location / {
            return 404;
        }

        location ~ \.(?:jpg|jpeg|js|css|gif|png|swf|ico|pdf)$ {
            expires        365d;
            access_log     off;
       	    add_header Pragma public;
            add_header Cache-Control "public, must-revalidate, proxy-revalidate";
        }
    }

```

On va s’arrêter là pour aujourd’hui. Si j’ai le courage de faire une
deuxième partie, on parlera de php-fpm,
de [mysql-master-ha](https://code.google.com/p/mysql-master-ha/ "MMHA") et
de [Icinga](https://www.icinga.org/ "Icinga").

